# iris/interfazIris.py
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import seaborn as sns
from iris.iris import IrisProcessor

def show_iris():
    """
    Interfaz de Streamlit para el dataset Iris
    SOLO muestra resultados llamando funciones del procesador
    """
    
    st.markdown("## An√°lisis del Dataset Iris")
    
    # Inicializar procesador en session state
    if 'iris_processor' not in st.session_state:
        st.session_state.iris_processor = IrisProcessor()
    
    processor = st.session_state.iris_processor
    
    # ===== TABS =====
    tabs = st.tabs([
        "üìä Dataset Original",
        "üìà Estad√≠sticas",
        "üîß Estandarizaci√≥n",
        "‚úÇÔ∏è Divisi√≥n de Datos",
        "üìâ Visualizaciones",
        "üé® An√°lisis Avanzado"
    ])
    
    # ==================== TAB 1: DATASET ORIGINAL ====================
    with tabs[0]:
        st.markdown("### üì• Carga del Dataset Iris")
        st.markdown("*Dataset disponible en sklearn.datasets*")
        
        if st.button("üîÑ Cargar Dataset Iris", type="primary", key="load_btn"):
            # LLAMAR funci√≥n de carga
            result = processor.load_data()
            
            if result['success']:
                st.success(result['message'])
                
                # Mostrar m√©tricas
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("üìã Total de Muestras", result['rows'])
                with col2:
                    st.metric("üìä Caracter√≠sticas", result['columns'])
                with col3:
                    st.metric("üè∑Ô∏è Clases", len(result['classes']))
                with col4:
                    st.metric("‚öñÔ∏è Muestras por Clase", "50")
                
                # Informaci√≥n de caracter√≠sticas
                st.markdown("#### üìã Caracter√≠sticas del Dataset")
                st.info(f"**Caracter√≠sticas:** {', '.join(result['features'])}")
                st.info(f"**Clases:** {', '.join(result['classes'])}")
                
                # Distribuci√≥n de clases
                st.markdown("#### üè∑Ô∏è Distribuci√≥n de Clases")
                samples_per_class = result['samples_per_class']
                
                col1, col2, col3 = st.columns(3)
                for idx, (class_name, count) in enumerate(zip(result['classes'], samples_per_class.values())):
                    with [col1, col2, col3][idx]:
                        st.metric(class_name, count)
                
                # Mostrar datos originales
                df_original = processor.get_original_data()
                
                st.markdown("#### üìã Vista previa del dataset")
                st.dataframe(df_original.head(15), use_container_width=True)
                
                st.markdown("#### üìä Dataset completo")
                st.dataframe(df_original, use_container_width=True)
            else:
                st.error(result['message'])
    
    # ==================== TAB 2: ESTAD√çSTICAS ====================
    with tabs[1]:
        st.markdown("### üìà Estad√≠sticas Descriptivas")
        
        if not processor.is_loaded():
            st.warning("‚ö†Ô∏è Primero debes cargar el dataset en la pesta√±a 'Dataset Original'")
        else:
            # LLAMAR funci√≥n de estad√≠sticas
            stats = processor.get_basic_statistics()
            
            if stats:
                st.markdown("#### üìä Estad√≠sticas Descriptivas")
                st.dataframe(stats['describe'], use_container_width=True)
                
                st.markdown("#### üîó Matriz de Correlaci√≥n")
                
                # Heatmap de correlaci√≥n
                fig = px.imshow(
                    stats['correlation'],
                    text_auto='.2f',
                    labels=dict(color="Correlaci√≥n"),
                    color_continuous_scale='RdBu_r',
                    aspect="auto"
                )
                fig.update_layout(
                    title='Correlaci√≥n entre Caracter√≠sticas',
                    width=700,
                    height=600
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Interpretaci√≥n de correlaciones
                st.markdown("#### üí° Observaciones")
                corr = stats['correlation']
                
                # Encontrar la correlaci√≥n m√°s fuerte (excluyendo diagonal)
                corr_values = []
                for i in range(len(corr)):
                    for j in range(i+1, len(corr)):
                        corr_values.append({
                            'features': f"{corr.index[i]} - {corr.columns[j]}",
                            'value': corr.iloc[i, j]
                        })
                
                strongest = max(corr_values, key=lambda x: abs(x['value']))
                st.info(f"üîç **Correlaci√≥n m√°s fuerte:** {strongest['features']} ({strongest['value']:.3f})")
    
    # ==================== TAB 3: ESTANDARIZACI√ìN ====================
    with tabs[2]:
        st.markdown("### üîß Estandarizaci√≥n con StandardScaler")
        st.markdown("*Aplica transformaci√≥n Z-score: (x - Œº) / œÉ*")
        
        if not processor.is_loaded():
            st.warning("‚ö†Ô∏è Primero debes cargar el dataset en la pesta√±a 'Dataset Original'")
        else:
            if st.button("‚ö° Aplicar Estandarizaci√≥n", type="primary", key="scale_btn"):
                # LLAMAR funci√≥n de estandarizaci√≥n
                result = processor.apply_standardization()
                
                if result['success']:
                    st.success(result['message'])
                    
                    st.markdown("#### üìä Comparaci√≥n: Antes vs Despu√©s")
                    
                    # Mostrar para cada caracter√≠stica
                    for feature in result['features_scaled']:
                        with st.expander(f"üìà {feature}"):
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.markdown("**Antes de Estandarizar:**")
                                st.write(f"Media: {result['stats_before']['mean'][feature]:.3f}")
                                st.write(f"Desv. Est√°ndar: {result['stats_before']['std'][feature]:.3f}")
                                st.write(f"M√≠nimo: {result['stats_before']['min'][feature]:.3f}")
                                st.write(f"M√°ximo: {result['stats_before']['max'][feature]:.3f}")
                            
                            with col2:
                                st.markdown("**Despu√©s de Estandarizar:**")
                                st.write(f"Media: {result['stats_after']['mean'][feature]:.6f}")
                                st.write(f"Desv. Est√°ndar: {result['stats_after']['std'][feature]:.6f}")
                                st.write(f"M√≠nimo: {result['stats_after']['min'][feature]:.3f}")
                                st.write(f"M√°ximo: {result['stats_after']['max'][feature]:.3f}")
                    
                    # Par√°metros del scaler
                    st.markdown("#### ‚öôÔ∏è Par√°metros del StandardScaler")
                    scaler_params = pd.DataFrame({
                        'Feature': result['features_scaled'],
                        'Mean (Œº)': result['scaler_params']['mean'],
                        'Scale (œÉ)': result['scaler_params']['scale']
                    })
                    st.dataframe(scaler_params, use_container_width=True)
                    
                    # Mostrar estad√≠sticas del dataset escalado
                    st.markdown("#### üìã Estad√≠sticas Descriptivas del Dataset Estandarizado")
                    scaled_stats = processor.get_scaled_statistics()
                    st.dataframe(scaled_stats['describe'], use_container_width=True)
                else:
                    st.error(result['message'])
    
    # ==================== TAB 4: DIVISI√ìN DE DATOS ====================
    with tabs[3]:
        st.markdown("### ‚úÇÔ∏è Divisi√≥n de Datos")
        st.markdown("*70% Entrenamiento - 30% Prueba*")
        
        if not processor.is_scaled():
            st.warning("‚ö†Ô∏è Primero debes aplicar estandarizaci√≥n en la pesta√±a 'Estandarizaci√≥n'")
        else:
            if st.button("‚úÇÔ∏è Dividir Datos (70-30)", type="primary", key="split_btn"):
                # LLAMAR funci√≥n de divisi√≥n
                result = processor.split_data(test_size=0.3, random_state=42)
                
                if result['success']:
                    st.success(result['message'])
                    
                    # M√©tricas principales
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("#### üéØ Conjunto de Entrenamiento (70%)")
                        st.metric("X_train", str(result['X_train_shape']))
                        st.metric("y_train", str(result['y_train_shape']))
                        st.metric("Total Muestras", result['train_samples'])
                        
                        st.markdown("**Distribuci√≥n de Clases:**")
                        for class_id, count in result['train_class_distribution'].items():
                            class_name = processor.get_target_names()[int(class_id)]
                            st.write(f"‚Ä¢ {class_name}: {count} muestras")
                    
                    with col2:
                        st.markdown("#### üß™ Conjunto de Prueba (30%)")
                        st.metric("X_test", str(result['X_test_shape']))
                        st.metric("y_test", str(result['y_test_shape']))
                        st.metric("Total Muestras", result['test_samples'])
                        
                        st.markdown("**Distribuci√≥n de Clases:**")
                        for class_id, count in result['test_class_distribution'].items():
                            class_name = processor.get_target_names()[int(class_id)]
                            st.write(f"‚Ä¢ {class_name}: {count} muestras")
                    
                    # Gr√°fico de divisi√≥n
                    fig = go.Figure(data=[
                        go.Pie(
                            labels=['Entrenamiento (70%)', 'Prueba (30%)'],
                            values=[result['train_samples'], result['test_samples']],
                            marker_colors=['#3498db', '#e74c3c'],
                            hole=0.3
                        )
                    ])
                    fig.update_layout(title='Divisi√≥n del Dataset')
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.error(result['message'])
    
    # ==================== TAB 5: VISUALIZACIONES ====================
    with tabs[4]:
        st.markdown("### üìâ Visualizaciones del Dataset")
        
        if not processor.is_loaded():
            st.warning("‚ö†Ô∏è Primero debes cargar el dataset en la pesta√±a 'Dataset Original'")
        else:
            # GR√ÅFICO DE DISPERSI√ìN
            st.markdown("#### üéØ Gr√°fico de Dispersi√≥n: Sepal Length vs Petal Length")
            st.markdown("*Diferenciado por clase (target)*")
            
            # LLAMAR funci√≥n para obtener datos
            scatter_data = processor.get_scatter_data(
                feature_x='sepal length (cm)',
                feature_y='petal length (cm)'
            )
            
            if scatter_data:
                # Crear DataFrame para plotly
                df_scatter = pd.DataFrame({
                    'Sepal Length': scatter_data['x'],
                    'Petal Length': scatter_data['y'],
                    'Species': scatter_data['species']
                })
                
                # Gr√°fico con Plotly
                fig = px.scatter(
                    df_scatter,
                    x='Sepal Length',
                    y='Petal Length',
                    color='Species',
                    title='Sepal Length vs Petal Length por Especie',
                    labels={
                        'Sepal Length': 'Longitud del S√©palo (cm)',
                        'Petal Length': 'Longitud del P√©talo (cm)'
                    },
                    color_discrete_sequence=['#e74c3c', '#3498db', '#2ecc71']
                )
                fig.update_traces(marker=dict(size=10, line=dict(width=1, color='white')))
                fig.update_layout(height=600)
                st.plotly_chart(fig, use_container_width=True)
                
                # Gr√°fico con Matplotlib (alternativa)
                st.markdown("#### üìä Gr√°fico Alternativo con Matplotlib")
                
                fig_mpl, ax = plt.subplots(figsize=(10, 6))
                
                colors = {0: '#e74c3c', 1: '#3498db', 2: '#2ecc71'}
                target_names = processor.get_target_names()
                
                for target_value in [0, 1, 2]:
                    mask = scatter_data['target'] == target_value
                    ax.scatter(
                        scatter_data['x'][mask],
                        scatter_data['y'][mask],
                        c=colors[target_value],
                        label=target_names[target_value],
                        s=100,
                        alpha=0.6,
                        edgecolors='white',
                        linewidth=1.5
                    )
                
                ax.set_xlabel('Longitud del S√©palo (cm)', fontsize=12)
                ax.set_ylabel('Longitud del P√©talo (cm)', fontsize=12)
                ax.set_title('Sepal Length vs Petal Length por Especie', fontsize=14, fontweight='bold')
                ax.legend(title='Especie', fontsize=10)
                ax.grid(True, alpha=0.3)
                
                st.pyplot(fig_mpl)
            
            # DISTRIBUCIONES POR CARACTER√çSTICA
            st.markdown("#### üìä Distribuci√≥n de Caracter√≠sticas por Especie")
            
            # LLAMAR funci√≥n para obtener distribuciones
            distributions = processor.get_feature_distributions()
            
            if distributions:
                feature_names = processor.get_feature_names()
                
                # Crear gr√°fico de 4 subplots
                for feature in feature_names:
                    data = distributions[feature]
                    
                    df_dist = pd.DataFrame({
                        'Value': data['values'],
                        'Species': data['species']
                    })
                    
                    fig = px.histogram(
                        df_dist,
                        x='Value',
                        color='Species',
                        title=f'Distribuci√≥n de {feature}',
                        labels={'Value': feature, 'count': 'Frecuencia'},
                        barmode='overlay',
                        opacity=0.7,
                        color_discrete_sequence=['#e74c3c', '#3498db', '#2ecc71']
                    )
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)
    
    # ==================== TAB 6: AN√ÅLISIS AVANZADO ====================
    with tabs[5]:
        st.markdown("### üé® An√°lisis Avanzado")
        
        if not processor.is_loaded():
            st.warning("‚ö†Ô∏è Primero debes cargar el dataset en la pesta√±a 'Dataset Original'")
        else:
            # PAIRPLOT
            st.markdown("#### üî≤ Pairplot: Relaciones entre Caracter√≠sticas")
            st.markdown("*Visualizaci√≥n de todas las combinaciones de caracter√≠sticas*")
            
            if st.button("üé® Generar Pairplot", key="pairplot_btn"):
                with st.spinner("Generando pairplot..."):
                    # LLAMAR funci√≥n para obtener datos
                    df_pairplot = processor.get_pairplot_data()
                    
                    if df_pairplot is not None:
                        # Crear pairplot con seaborn
                        fig = sns.pairplot(
                            df_pairplot,
                            hue='species',
                            palette={'setosa': '#e74c3c', 'versicolor': '#3498db', 'virginica': '#2ecc71'},
                            diag_kind='hist',
                            plot_kws={'alpha': 0.6, 'edgecolor': 'white'},
                            height=2.5
                        )
                        fig.fig.suptitle('Pairplot del Dataset Iris', y=1.01, fontsize=16, fontweight='bold')
                        st.pyplot(fig.fig)
                        
                        st.success("‚úÖ Pairplot generado exitosamente")
                        
                        st.markdown("#### üí° Interpretaci√≥n del Pairplot")
                        st.info("""
                        - **Diagonal:** Histogramas de cada caracter√≠stica por especie
                        - **Fuera de diagonal:** Gr√°ficos de dispersi√≥n entre pares de caracter√≠sticas
                        - **Setosa** se distingue claramente por su s√©palo corto y ancho
                        - **Petal length y Petal width** son las caracter√≠sticas m√°s discriminantes
                        """)
            
            st.markdown("---")
            
            # PCA 3D
            st.markdown("#### üé≤ An√°lisis de Componentes Principales (PCA)")
            st.markdown("*Reducci√≥n a 3 dimensiones principales*")
            
            if st.button("üìä Generar PCA 3D", key="pca_btn"):
                with st.spinner("Calculando PCA..."):
                    # LLAMAR funci√≥n de PCA
                    pca_result = processor.get_pca_data(n_components=3)
                    
                    if pca_result['success']:
                        st.success("‚úÖ PCA calculado exitosamente")
                        
                        # Informaci√≥n de varianza explicada
                        st.markdown("#### üìä Varianza Explicada")
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric("PC1", f"{pca_result['explained_variance'][0]*100:.1f}%")
                        with col2:
                            st.metric("PC2", f"{pca_result['explained_variance'][1]*100:.1f}%")
                        with col3:
                            st.metric("PC3", f"{pca_result['explained_variance'][2]*100:.1f}%")
                        with col4:
                            st.metric("Total", f"{pca_result['total_variance']*100:.1f}%")
                        
                        # Gr√°fico 3D con Plotly
                        st.markdown("#### üé≤ Visualizaci√≥n PCA en 3D")
                        
                        X_pca = pca_result['X_pca']
                        species = pca_result['species']
                        
                        df_pca = pd.DataFrame({
                            'PC1': X_pca[:, 0],
                            'PC2': X_pca[:, 1],
                            'PC3': X_pca[:, 2],
                            'Species': species
                        })
                        
                        fig = px.scatter_3d(
                            df_pca,
                            x='PC1',
                            y='PC2',
                            z='PC3',
                            color='Species',
                            title='Primeras 3 Componentes Principales del Dataset Iris',
                            labels={
                                'PC1': '1er Componente Principal',
                                'PC2': '2do Componente Principal',
                                'PC3': '3er Componente Principal'
                            },
                            color_discrete_sequence=['#e74c3c', '#3498db', '#2ecc71']
                        )
                        
                        fig.update_traces(marker=dict(size=6, line=dict(width=0.5, color='white')))
                        fig.update_layout(height=700)
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        st.markdown("#### üí° Interpretaci√≥n del PCA")
                        st.info(f"""
                        - Las 3 componentes principales explican el **{pca_result['total_variance']*100:.1f}%** de la varianza total
                        - Se observa una clara separaci√≥n entre las especies en el espacio reducido
                        - **Setosa** es la m√°s f√°cil de distinguir
                        - **Versicolor** y **Virginica** tienen cierta superposici√≥n pero son distinguibles
                        """)